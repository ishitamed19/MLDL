{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#### importing dependencies\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Model, load_model, Sequential, model_from_yaml # to save our weights and load the pre-trained weights model\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Importing the dataset\n",
    "\n",
    "def read_data(path):\n",
    "    print(\"Loading text data...\")\n",
    "    text = io.open(path, encoding='utf-8').read().lower()\n",
    "    print(\"Done.\")\n",
    "    print(\"Corpus Length:\", len(text))\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text data...\n",
      "Done.\n",
      "Corpus Length: 1967249\n"
     ]
    }
   ],
   "source": [
    "text=read_data('ramayana.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique characters in the corpus: 83\n"
     ]
    }
   ],
   "source": [
    "#### Calculating the number of characters stored and building the c_to_i dictionary\n",
    "\n",
    "chars=sorted(list(set(text)))\n",
    "\n",
    "print('number of unique characters in the corpus:', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "Tx = 40 # sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Helper functions to build (train examples & labels) the dataset & vectorize it\n",
    "\n",
    "def build_data(text, Tx = 40, steps = 3):\n",
    "    \"\"\"Create a training set by scanning a window of size Tx over the text corpus, with a stride of 3.\"\"\"\n",
    "    X = [] # training examples (list)\n",
    "    Y = [] # training labels (list)\n",
    "    for i in range(0, len(text) - Tx, steps):\n",
    "        X.append(text[i: i + Tx])\n",
    "        Y.append(text[i + Tx])\n",
    "    print('number of training examples:', len(X))\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def vectorization(X, Y, n_x, char_indices, Tx = 40):\n",
    "    \"\"\"Convert X and Y (lists) into arrays to be given to a recurrent neural network.\"\"\"\n",
    "    \n",
    "    m = len(X)\n",
    "    x = np.zeros((m, Tx, n_x), dtype=np.bool) # array of shape (m, Tx, len(chars))\n",
    "    y = np.zeros((m, n_x), dtype=np.bool) # array of shape (m, len(chars))\n",
    "    for i, sentence in enumerate(X):\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[Y[i]]] = 1\n",
    "        \n",
    "    return x, y \n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    out = np.random.choice(range(len(chars)), p = probas.ravel())\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: 655737\n"
     ]
    }
   ],
   "source": [
    "#### Building the data and Vectorizing it\n",
    "\n",
    "X, Y = build_data(text, Tx=40, steps=3)\n",
    "x, y = vectorization(X, Y, n_x = len(chars), char_indices = char_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "#### Defining the Model\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(Tx, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function invoked at end of each epoch. Prints generated text.\n",
    "\n",
    "def on_epoch_end(epoch, logs, maxlen=Tx):\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    diversity=0.4\n",
    "\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    #usr_input = input(\"Write the beginning sentence and machine will complete it. Your input is: \")\n",
    "    # zero pad the sentence to Tx characters.\n",
    "    #sentence = ('{0:0>' + str(Tx) + '}').format(usr_input).lower()\n",
    "    #generated += usr_input\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(1000):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        if next_char == '\\n':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "655616/655737 [============================>.] - ETA: 0s - loss: 1.7088\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"shore,\n",
      "and, deeming that all hope was lo\"\n",
      "shore,\n",
      "and, deeming that all hope was lord,\n",
      "the sangless and the monarch steed,\n",
      "with the will lord and realm the soul,\n",
      "and there the good in speatles to see,\n",
      "and brave the king the sangure stay,\n",
      "the stream in the his angues to the giant speech\n",
      "and for the son in sangs the stand\n",
      "of all the consolled the strong.\n",
      "then with the brothers to the soul.\n",
      "and still the consort on the sangle,\n",
      "the words the spite of her the speech and pride\n",
      "and world the streef the world, and speech.\n",
      "the souther of the saint to see,\n",
      "and can i see the words the near,\n",
      "and standed the comman dread.\n",
      "the giant still the lord of the be\n",
      "the stranger to the words to streed.\n",
      "the sage and forth the trees to see,\n",
      "and holy roins with sent the side,\n",
      "where soul the mighty soul the be\n",
      "the words the words the world to streed.\n",
      "the path the sang the good and ear.\n",
      "the sangar stayed the hand and break,\n",
      "and the good and sped the strong,\n",
      "and her the soul the word in spread,\n",
      "the counselled the giant spear.\n",
      "the consellowed the wind the sangh,\n",
      "655737/655737 [==============================] - 401s 612us/step - loss: 1.7087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120bf4c88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Generating the output\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_yaml = model.to_yaml()\\nwith open(\"ramayana_model.yaml\", \"w\") as yaml_file:\\n    yaml_file.write(model_yaml)\\n\\nmodel.save_weights(\"ramayana_model.h5\")\\nprint(\"Saved model to disk\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving weights and model\n",
    "\"\"\"\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"ramayana_model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "model.save_weights(\"ramayana_model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
